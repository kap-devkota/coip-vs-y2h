---
title: "r-tests"
output: html_document
date: "2023-06-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("dplyr")
# install.packages("igraph")
library("igraph")
```

## Test 1: Are the Co-IP and Y2H networks structurally similar?

In this test, we try to find out how often does the triadic closure motiff occur in $G_c$ and $G_y$.

```{r test1-setup}
dgc <- read.csv("../data/networks/coip_hc_full.tsv", sep = "\t", header = FALSE)
dgy <- read.csv("../data/networks/y2h_hc_full.tsv", sep = "\t", header = FALSE)

# Ordering the columns of both Gc and Gy

dgc[which(dgc$V1 > dgc$V2), c("V1", "V2")] <- dgc[which(dgc$V1 > dgc$V2), c("V2", "V1")]
dgy[which(dgy$V1 > dgy$V2), c("V1", "V2")] <- dgy[which(dgy$V1 > dgy$V2), c("V2", "V1")]
```

Find $G$ from $G_c$ and $G_y$ by finding all the common nodes and edges between them.

```{r test1-findG}
dG <- merge(dgc, dgy, by.x = c("V1", "V2"), by.y= c("V1", "V2"), all.x = FALSE, all.y = FALSE)
dG[c("V1", "V2")]
```

Compute the actual iGraph $G$.

```{r test1-create-graph}
G <- graph_from_data_frame(dG[c("V1", "V2")], directed = FALSE) #, vertices = nodesG)
default_triangles <- length(triangles(G))
default_triangles
```

Now, we start the experiment by randomly adding edges in $G$ corresponding to $G_c$ and $G_y$

```{r test1-get-nodes}
Gnodes <- V(G)$name
Gcnodes <- union(dgc$V1, dgc$V2)
Gynodes <- union(dgy$V1, dgy$V2)
Gcmissing <- setdiff(Gcnodes, Gnodes)
Gymissing <- setdiff(Gynodes, Gnodes)

# DEBUG
c(length(Gnodes), length(Gcnodes), length(Gynodes), length(Gcmissing), length(Gymissing))


monte_carlo <- function(n_simulations, callback, ...) {
  simulations <- 1:n_simulations
  sapply(1:n_simulations, function(x){callback(...)})
}

# Given the test data-frame, common graph and sampled nodes, return the 
# length of triangles
sample_triangles <- function(dfGtest, Gcommon, missing_nodes, no_nodes, no_edges) {
  sampled_nodes <- sample(missing_nodes, no_nodes)
  nodestoadd <- union(sampled_nodes, V(Gcommon)$name)
  edgetoadd  <- dfGtest[which(dfGtest$V1 %in% nodestoadd & dfGtest$V2 %in% nodestoadd), c("V1", "V2")]
  edgetoadd <- edgetoadd[sample(nrow(edgetoadd), no_edges), ]
  gtoadd <- graph_from_data_frame(edgetoadd, directed = FALSE)
  g <- gtoadd %u% Gcommon
  return(length(triangles(g)))
}
```

Now we run tests for different edge and node combinations

```{r test1-run-gc}
gc_tcounts <- c()
E <- c(50, 100, 200, 300, 400, 500, 1000)
K <- c(10, 20, 30, 40, 50, 100)
n_simulations <- 50

results <- expand.grid(E, K)
colnames(results) <- c("Edges", "Nodes")
results$pvalues <- apply(results, MARGIN=1, function(a) {
  e <- a[1]
  k <- a[2]
  gc_counts <- monte_carlo(n_simulations, sample_triangles, 
                           dgc, G, Gcmissing, k, e)
  gy_counts <- monte_carlo(n_simulations, sample_triangles, 
                           dgy, G, Gymissing, k, e)
  res <- t.test(gc_counts, gy_counts)
  return(res$p.value)
})

write.table(results, "test1-results.tsv", sep = "\t", row.names = FALSE)
```

Seeing the results for different Edge and Node combinations, even after applying multiple testing correction (Bonnoferoni), the alternate hypothesis is still accepted for all edges and nodes combinations.

## Test 2: Are do the networks see new likely links differently, provided some link-prediction functions

Here, we test using two Link Prediction Algorithms:

1.  Common Weighted
2.  L3

```{r test2-setup}
dgc <- read.csv("../data/networks/coip_hc_full.tsv", sep = "\t", header = FALSE)
dgy <- read.csv("../data/networks/y2h_hc_full.tsv", sep = "\t", header = FALSE)

# Ordering the columns of both Gc and Gy

dgc[which(dgc$V1 > dgc$V2), c("V1", "V2")] <- dgc[which(dgc$V1 > dgc$V2), c("V2", "V1")]
dgy[which(dgy$V1 > dgy$V2), c("V1", "V2")] <- dgy[which(dgy$V1 > dgy$V2), c("V2", "V1")]
```

Get the shared version of $G_c$ and $G_y$, by selecting all the edges associated with common nodes between the two networks.
```{r test2-get-common}
gcnodes <- union(dgc[[1]], dgc[[2]])
gynodes <- union(dgy[[1]], dgy[[2]])

gcommon <- intersect(gcnodes, gynodes)
dgc_s <- dgc[which(dgc[[1]] %in% gcommon & dgc[[2]] %in% gcommon), ]
dgy_s <- dgy[which(dgy[[1]] %in% gcommon & dgy[[2]] %in% gcommon), ]

gcommon <- intersect(union(dgy_s$V1, dgy_s$V2), union(dgc_s$V1, dgc_s$V2))

list(dgc_s,dgy_s)
```

Now, define the link prediction functions `L3` and `CWN`
```{r test2-utilities}
library(Matrix)
library(MASS)
library(mnormt)


CWN <- function(mat) {
  deg <- apply(mat, 1, sum)
  Deg1_2 <- as(diag(1 / sqrt(deg)), "sparseMatrix")
  row.names(Deg1_2) <- rownames(mat)
  colnames(Deg1_2) <- colnames(mat)
  mask <- mat
  mask[mask > 0] <- 1
  cw <- mat %*% mask + mask %*% mat
  cw <- Deg1_2 %*% cw %*% Deg1_2
  return(cw)
}

L3 <- function(mat) {
  deg <- apply(mat, 1, sum)
  Deg1_2 <- as(diag(1 / sqrt(deg)), "sparseMatrix")
  mat1 <- Deg1_2 %*% mat %*% Deg1_2
  return(mat %*% mat1 %*% mat)
}

DSD <- function(mat, epsilon=1e-5, gamma = 1, normal=TRUE) {
  d <- apply(mat, 1, sum)
  
  d[d == 0] <- epsilon
  d_all <- sum(d)
  d_1 <- 1 / d
  
  P <- A 
}
```

Now, we randomly generate node-pairs of size $K$, that are not present in either of the shared networks
```{r test2-generate-samples}
N <- 500
dgcy_s <- rbind(dgc_s[c("V1", "V2")], dgy_s[c("V1", "V2")])
dgcy_s <- dgcy_s[!duplicated(dgcy_s), ]

get_k_samples <- function(df, nodes, n_samples) {
  sampled_list <- as.data.frame(do.call(rbind, lapply(1:as.integer(n_samples * 1.5), function(i) {sample(nodes, 2, replace=FALSE)})))
  sampled_list[which(sampled_list$V1 > sampled_list$V2), c("V1", "V2")] <-  sampled_list[which(sampled_list$V1 > sampled_list$V2), c("V2", "V1")]
  return(anti_join(sampled_list, df, by=c("V1", "V2"))[1:n_samples, ])
}

results <- expand.grid(c(100, 200, 300, 400, 500), 1:5)
colnames(results) <- c("No-samples", "Iteration")

Coip <- graph.data.frame(dgc_s, directed = FALSE)
Coip_mat <- get.adjacency(Coip, sparse = FALSE, attr='V3')
Coip_mat <- as(Coip_mat, "sparseMatrix")

Y2h <- graph.data.frame(dgy_s, directed = FALSE)
Y2h_mat <- get.adjacency(Y2h, sparse = FALSE, attr='V3')
Y2h_mat <- as(Y2h_mat, "sparseMatrix")


CWMat_coip <- CWN(Coip_mat)
CWMat_y2h <- CWN(Y2h_mat)

L3Mat_coip <- L3(Coip_mat)
L3Mat_y2h <- L3(Y2h_mat)

get_scores <- function(samples, mat, coln) {
  samples$coln <- apply(samples, 1, function(x) {return(mat[x[[0]], x[[1]]])})
}

samples <- get_k_samples(dgcy_s, gcommon, 500)
samples$l3_coip <- apply(samples, 1, function(x) {return(L3Mat_coip[x[[1]], x[[2]]])})
samples$l3_y2h <- apply(samples, 1, function(x) {return(L3Mat_y2h[x[[1]], x[[2]]])})
sum(samples$l3_y2h != 0)
```

## Test 3: 
